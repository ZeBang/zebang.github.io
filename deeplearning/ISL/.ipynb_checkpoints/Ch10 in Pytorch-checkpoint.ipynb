{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7c2541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "683bfedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "def synthetic_data(m, c, num_examples):\n",
    "    X = torch.normal(0, 1, (num_examples, len(m)))\n",
    "    y = torch.matmul(X, m) + c\n",
    "    y += torch.normal(0, 0.01, y.shape)\n",
    "    return X, y.reshape((-1, 1))\n",
    "\n",
    " \n",
    "true_m = torch.tensor([2, -3.4, 1])\n",
    "true_c = 4.2\n",
    "x_train, y_train = synthetic_data(true_m, true_c, 1000)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3d79667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 3])\n",
      "torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# create dummy data for training\n",
    "x_train = torch.normal(0, 1, (1000, 3))\n",
    "y_train = (torch.matmul(x_train, true_m) + true_c).reshape(-1, 1)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46d9f9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Read dataset and create small batch\n",
    " \n",
    "#define a function to create a data iterator. Input is the features and labels from synthetic data\n",
    " \n",
    "# Output is iterable batched data using torch.utils.data.DataLoader\n",
    " \n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    " \n",
    "\n",
    "batch_size = 5\n",
    " \n",
    "data_iter = load_array((x_train, y_train), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb4b5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(data_iter))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26cc1944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 960.397442\n",
      "epoch 2, loss 0.340357\n",
      "epoch 3, loss 0.000130\n",
      "epoch 4, loss 0.000000\n",
      "epoch 5, loss 0.000000\n",
      "epoch 6, loss 0.000000\n",
      "epoch 7, loss 0.000000\n",
      "epoch 8, loss 0.000000\n",
      "epoch 9, loss 0.000000\n",
      "epoch 10, loss 0.000000\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1)\n",
    "#         self.fc2 = nn.Linear(50, 1)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net(3)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss_epoch = 0\n",
    "    for x,y in data_iter:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(net(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "    print(f'epoch {epoch + 1}, loss {loss_epoch:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540fc4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53809b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a45c66be",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bccabe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gitters = pd.read_csv('Gitters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81f74acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv('x.csv').iloc[:,1:].to_numpy()\n",
    "y = Gitters[\"Salary\"].to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f25b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.from_numpy(x).float()\n",
    "y_train = torch.from_numpy(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "157d9e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([263, 20])\n",
      "torch.Size([263, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5357fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 50\n",
    "data_iter = load_array((x_train, y_train), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc916d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 2527293.593750\n",
      "epoch 2, loss 2044335.890625\n",
      "epoch 3, loss 1560727.312500\n",
      "epoch 4, loss 1334084.812500\n",
      "epoch 5, loss 1369633.523438\n",
      "epoch 6, loss 1059210.671875\n",
      "epoch 7, loss 999053.578125\n",
      "epoch 8, loss 894675.578125\n",
      "epoch 9, loss 872914.984375\n",
      "epoch 10, loss 871751.226562\n",
      "epoch 11, loss 757872.875000\n",
      "epoch 12, loss 738396.445312\n",
      "epoch 13, loss 686884.675781\n",
      "epoch 14, loss 778385.699219\n",
      "epoch 15, loss 649754.253906\n",
      "epoch 16, loss 686026.156250\n",
      "epoch 17, loss 684457.085938\n",
      "epoch 18, loss 726876.468750\n",
      "epoch 19, loss 615254.191406\n",
      "epoch 20, loss 705209.328125\n",
      "epoch 21, loss 657457.964844\n",
      "epoch 22, loss 639087.109375\n",
      "epoch 23, loss 682426.316406\n",
      "epoch 24, loss 605213.320312\n",
      "epoch 25, loss 605484.777344\n",
      "epoch 26, loss 573221.992188\n",
      "epoch 27, loss 674553.070312\n",
      "epoch 28, loss 612534.437500\n",
      "epoch 29, loss 600221.148438\n",
      "epoch 30, loss 599354.226562\n",
      "epoch 31, loss 882088.054688\n",
      "epoch 32, loss 620328.515625\n",
      "epoch 33, loss 637519.378906\n",
      "epoch 34, loss 631249.734375\n",
      "epoch 35, loss 595727.121094\n",
      "epoch 36, loss 602467.761719\n",
      "epoch 37, loss 635229.890625\n",
      "epoch 38, loss 585290.417969\n",
      "epoch 39, loss 579654.839844\n",
      "epoch 40, loss 604098.695312\n",
      "epoch 41, loss 821495.011719\n",
      "epoch 42, loss 603825.367188\n",
      "epoch 43, loss 574805.089844\n",
      "epoch 44, loss 568249.394531\n",
      "epoch 45, loss 677051.941406\n",
      "epoch 46, loss 842862.656250\n",
      "epoch 47, loss 607183.515625\n",
      "epoch 48, loss 585059.562500\n",
      "epoch 49, loss 564166.363281\n",
      "epoch 50, loss 593593.406250\n",
      "epoch 51, loss 651651.457031\n",
      "epoch 52, loss 647975.312500\n",
      "epoch 53, loss 833639.125000\n",
      "epoch 54, loss 598932.785156\n",
      "epoch 55, loss 578845.546875\n",
      "epoch 56, loss 547993.527344\n",
      "epoch 57, loss 672561.320312\n",
      "epoch 58, loss 558584.324219\n",
      "epoch 59, loss 662028.937500\n",
      "epoch 60, loss 587946.679688\n",
      "epoch 61, loss 582197.636719\n",
      "epoch 62, loss 595105.203125\n",
      "epoch 63, loss 574019.773438\n",
      "epoch 64, loss 582042.097656\n",
      "epoch 65, loss 574883.164062\n",
      "epoch 66, loss 799630.523438\n",
      "epoch 67, loss 738501.726562\n",
      "epoch 68, loss 787359.582031\n",
      "epoch 69, loss 661062.328125\n",
      "epoch 70, loss 554500.191406\n",
      "epoch 71, loss 586684.054688\n",
      "epoch 72, loss 581283.792969\n",
      "epoch 73, loss 615897.773438\n",
      "epoch 74, loss 620083.136719\n",
      "epoch 75, loss 618449.113281\n",
      "epoch 76, loss 567656.210938\n",
      "epoch 77, loss 547909.339844\n",
      "epoch 78, loss 620838.902344\n",
      "epoch 79, loss 601816.824219\n",
      "epoch 80, loss 579966.218750\n",
      "epoch 81, loss 615223.214844\n",
      "epoch 82, loss 560987.382812\n",
      "epoch 83, loss 560393.332031\n",
      "epoch 84, loss 559722.289062\n",
      "epoch 85, loss 626755.984375\n",
      "epoch 86, loss 552485.902344\n",
      "epoch 87, loss 544155.351562\n",
      "epoch 88, loss 622434.210938\n",
      "epoch 89, loss 572528.562500\n",
      "epoch 90, loss 617682.335938\n",
      "epoch 91, loss 590162.226562\n",
      "epoch 92, loss 593954.593750\n",
      "epoch 93, loss 547446.988281\n",
      "epoch 94, loss 578620.773438\n",
      "epoch 95, loss 582171.046875\n",
      "epoch 96, loss 572753.773438\n",
      "epoch 97, loss 598024.835938\n",
      "epoch 98, loss 601102.589844\n",
      "epoch 99, loss 549393.605469\n",
      "epoch 100, loss 548130.392578\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1)\n",
    "#         self.fc2 = nn.Linear(50, 1)\n",
    "#         self.dropout = nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net(20)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "losses = []\n",
    "for epoch in range(100):\n",
    "    loss_epoch = 0\n",
    "    for x,y in data_iter:\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(net(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_epoch += loss.item()\n",
    "    print(f'epoch {epoch + 1}, loss {loss_epoch:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7e2bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65ed5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
